{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepLearning model API with docker container\n",
    "\n",
    "After saving the model (we'll assume that we already have the model in a folder with its folder name is the model name), we will create an API using the following steps:\n",
    "\n",
    "- Install Docker (link to download : https://docs.docker.com/desktop/install/windows-install/)\n",
    "- Install wsl2 (link to download : https://docs.microsoft.com/en-us/windows/wsl/install-manual#step-4---download-the-linux-kernel-update-package)\n",
    "- Run Docker\n",
    "- Open terminal / cmd and type :\n",
    "```bash\n",
    "docker pull tensorflow/serving\n",
    "docker run --rm -it -p 8500:8500 -p 8501:8501 -v \"/path/to/model/traffic_classifier:/models/traffic_classifier\"-e MODEL_NAME=traffic_classifier tensorflow/serving:latest\n",
    "```\n",
    "\n",
    "\n",
    "**Notes:** <br>\n",
    "*/path/to/model/traffic_classifier* is the path where we save the model. You can download my [saved model](https://github.com/marwanmusa/German-TrafficSign-Classification-CNN/tree/main/traffic_classifier) and saved it in your PC/Notebook.\n",
    "\n",
    "*MODEL_NAME* is our model name.\n",
    "\n",
    "if it success, then it will writes \"entering loop\" on the terminal.\n",
    "\n",
    "***This is how our API will look like***<br>\n",
    "http://localhost:8501/v1/models/traffic_classifier:predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Hands On***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fundamental classes\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Image related\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pydot\n",
    "\n",
    "# For ploting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For the model and it's training\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_directory = \"/path/to/model_folder\"\n",
    "train_path = \"/path/to/model_folder/Train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of each class\n",
    "classes = { 0:'Speed limit (20km/h)',\n",
    "            1:'Speed limit (30km/h)', \n",
    "            2:'Speed limit (50km/h)', \n",
    "            3:'Speed limit (60km/h)', \n",
    "            4:'Speed limit (70km/h)', \n",
    "            5:'Speed limit (80km/h)', \n",
    "            6:'End of speed limit (80km/h)', \n",
    "            7:'Speed limit (100km/h)', \n",
    "            8:'Speed limit (120km/h)', \n",
    "            9:'No passing', \n",
    "            10:'No passing veh over 3.5 tons', \n",
    "            11:'Right-of-way at intersection', \n",
    "            12:'Priority road', \n",
    "            13:'Yield', \n",
    "            14:'Stop', \n",
    "            15:'No vehicles', \n",
    "            16:'Veh > 3.5 tons prohibited', \n",
    "            17:'No entry', \n",
    "            18:'General caution', \n",
    "            19:'Dangerous curve left', \n",
    "            20:'Dangerous curve right', \n",
    "            21:'Double curve', \n",
    "            22:'Bumpy road', \n",
    "            23:'Slippery road', \n",
    "            24:'Road narrows on the right', \n",
    "            25:'Road work', \n",
    "            26:'Traffic signals', \n",
    "            27:'Pedestrians', \n",
    "            28:'Children crossing', \n",
    "            29:'Bicycles crossing', \n",
    "            30:'Beware of ice/snow',\n",
    "            31:'Wild animals crossing', \n",
    "            32:'End speed + passing limits', \n",
    "            33:'Turn right ahead', \n",
    "            34:'Turn left ahead', \n",
    "            35:'Ahead only', \n",
    "            36:'Go straight or right', \n",
    "            37:'Go straight or left', \n",
    "            38:'Keep right', \n",
    "            39:'Keep left', \n",
    "            40:'Roundabout mandatory', \n",
    "            41:'End of no passing', \n",
    "            42:'End no passing veh > 3.5 tons' }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference\n",
    "\n",
    "Finally, let's use our model to classify an image that wasn't included in the training or validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=30x30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data inference\n",
    "test_image = dataset_directory + r'/Test/00057.png'\n",
    "\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    test_image, target_size=([30, 30])\n",
    ")\n",
    "\n",
    "img # showing image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### This image most likely belongs to Traffic signals with a 6.08 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "# predicting with docker API\n",
    "import requests\n",
    "import json\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "# Processing\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "# json input\n",
    "input_data_json_img = json.dumps({\n",
    "    \"signature_name\": \"serving_default\",\n",
    "    \"instances\": img_array.tolist(),\n",
    "})\n",
    "\n",
    "# predicting\n",
    "URL = 'http://localhost:8501/v1/models/traffic_classifier:predict'\n",
    "response_img = requests.post(URL, data=input_data_json_img)\n",
    "response_img.raise_for_status() # raise an exception in case of error\n",
    "response_img = response_img.json()\n",
    "\n",
    "# predicting result\n",
    "score_img = tf.nn.softmax(response_img['predictions'][0])\n",
    "destination_by_img = classes[np.argmax(score_img)]\n",
    "\n",
    "# predicting result\n",
    "score = tf.nn.softmax(response_img['predictions'][0])\n",
    "print(\n",
    "    \"### This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(classes[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(43,), dtype=float32, numpy=\n",
       "array([0.02236222, 0.02236222, 0.02236222, 0.02236222, 0.02236222,\n",
       "       0.02236222, 0.02236222, 0.02236222, 0.02236222, 0.02236222,\n",
       "       0.02236222, 0.02236222, 0.02236222, 0.02236222, 0.02236222,\n",
       "       0.02236222, 0.02236222, 0.02236222, 0.02236222, 0.02236222,\n",
       "       0.02236222, 0.02236222, 0.02236222, 0.02236222, 0.02236222,\n",
       "       0.02236222, 0.06078682, 0.02236222, 0.02236222, 0.02236222,\n",
       "       0.02236222, 0.02236222, 0.02236222, 0.02236222, 0.02236222,\n",
       "       0.02236222, 0.02236222, 0.02236222, 0.02236222, 0.02236222,\n",
       "       0.02236222, 0.02236222, 0.02236222], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_img # what's in score_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom method for generating predictions\n",
    "def getPredictions(file_url):\n",
    "     # Fundamental classes\n",
    "        import numpy as np \n",
    "        import pandas as pd \n",
    "        import tensorflow\n",
    "        import os\n",
    "\n",
    "        # Image related\n",
    "        import cv2\n",
    "        from PIL import Image\n",
    "        import pydot\n",
    "\n",
    "        # For ploting\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        # For the model and it's training\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from tensorflow import keras\n",
    "        from tensorflow.keras.utils import to_categorical, plot_model\n",
    "        from tensorflow.keras.models import Sequential, load_model\n",
    "        from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "\n",
    "        # predicting with docker API\n",
    "        import requests\n",
    "        import json\n",
    "        from tensorflow.python.ops.numpy_ops import np_config\n",
    "        np_config.enable_numpy_behavior()\n",
    "        #\n",
    "        # Django image API\n",
    "        #\n",
    "\n",
    "        #\n",
    "        # classes\n",
    "        # Dictionary of each class\n",
    "        classes = { 0:'Speed limit (20km/h)',\n",
    "                    1:'Speed limit (30km/h)', \n",
    "                    2:'Speed limit (50km/h)', \n",
    "                    3:'Speed limit (60km/h)', \n",
    "                    4:'Speed limit (70km/h)', \n",
    "                    5:'Speed limit (80km/h)', \n",
    "                    6:'End of speed limit (80km/h)', \n",
    "                    7:'Speed limit (100km/h)', \n",
    "                    8:'Speed limit (120km/h)', \n",
    "                    9:'No passing', \n",
    "                    10:'No passing veh over 3.5 tons', \n",
    "                    11:'Right-of-way at intersection', \n",
    "                    12:'Priority road', \n",
    "                    13:'Yield', \n",
    "                    14:'Stop', \n",
    "                    15:'No vehicles', \n",
    "                    16:'Veh > 3.5 tons prohibited', \n",
    "                    17:'No entry', \n",
    "                    18:'General caution', \n",
    "                    19:'Dangerous curve left', \n",
    "                    20:'Dangerous curve right', \n",
    "                    21:'Double curve', \n",
    "                    22:'Bumpy road', \n",
    "                    23:'Slippery road', \n",
    "                    24:'Road narrows on the right', \n",
    "                    25:'Road work', \n",
    "                    26:'Traffic signals', \n",
    "                    27:'Pedestrians', \n",
    "                    28:'Children crossing', \n",
    "                    29:'Bicycles crossing', \n",
    "                    30:'Beware of ice/snow',\n",
    "                    31:'Wild animals crossing', \n",
    "                    32:'End speed + passing limits', \n",
    "                    33:'Turn right ahead', \n",
    "                    34:'Turn left ahead', \n",
    "                    35:'Ahead only', \n",
    "                    36:'Go straight or right', \n",
    "                    37:'Go straight or left', \n",
    "                    38:'Keep right', \n",
    "                    39:'Keep left', \n",
    "                    40:'Roundabout mandatory', \n",
    "                    41:'End of no passing', \n",
    "                    42:'End no passing veh > 3.5 tons' }\n",
    "        # loading\n",
    "        img = keras.preprocessing.image.load_img(file_url, target_size=([30, 30]))\n",
    "\n",
    "        # Processing\n",
    "        img_array = keras.preprocessing.image.img_to_array(img)\n",
    "        img_array = tensorflow.expand_dims(img_array, 0)\n",
    "\n",
    "        # json input\n",
    "        input_data_json_img = json.dumps({\n",
    "            \"signature_name\": \"serving_default\",\n",
    "            \"instances\": img_array.tolist(),\n",
    "        })\n",
    "\n",
    "        # predicting\n",
    "        # URL = 'https://traffic-classifier-backend.herokuapp.com/v1/models/traffic_classifier:predict'\n",
    "        URL = 'http://localhost:8501/v1/models/traffic_classifier:predict'\n",
    "        response_img = requests.post(URL, data=input_data_json_img)\n",
    "        response_img.raise_for_status() # raise an exception in case of error\n",
    "        response_img = response_img.json()\n",
    "\n",
    "        # predicting result\n",
    "        score_img = tensorflow.nn.softmax(response_img['predictions'][0])\n",
    "        destination_by_img = classes[np.argmax(score_img)]\n",
    "\n",
    "        # predicting result\n",
    "        score = tensorflow.nn.softmax(response_img['predictions'][0])\n",
    "        hbc = print(\n",
    "            \"### This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "            .format(classes[np.argmax(score)], 100 * np.max(score))\n",
    "        )\n",
    "        return hbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### This image most likely belongs to Traffic signals with a 6.08 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "getPredictions(test_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95164e0939ca81fba5fba16dede8865fbf3a070edba1eee9cb813c800a1f4e7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
